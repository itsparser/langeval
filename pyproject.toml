[project]
name = "langval"
version = "0.1.0"
description = "langval is a language model evaluation tool for evaluating the toxicity, accuracy, hallucination, and bias of language models."
authors = [
    { name = "Vasanth Kumar", email = "itsparser@gmail.com" },
    { name = "Adheeban", email = "iamadhee@gmail.com" },
]
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "langchain-core>=0.3.5",
    "langchain-ollama>=0.2.0",
    "langchain-openai>=0.2.0",
    "langchain>=0.3.0",
    "langgraph>=0.2.26",
    "ruff>=0.6.7",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
sources = ["src"]



[tool.ruff.lint]
select = ["F", "I"]
ignore = ["F401"]

[tool.ruff]
line-length = 100

[tool.ruff.format]
quote-style = "single"
indent-style = "tab"
docstring-code-format = true
docstring-code-line-length = 20
